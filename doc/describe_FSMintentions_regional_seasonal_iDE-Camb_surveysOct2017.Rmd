---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: svm-latex-ms.tex
title: "How Intentions Toward Fecal Sludge Management Vary Regionally and Seasonally in Rural Cambodia"
thanks: "**Current version**: `r format(Sys.time(), '%B %d, %Y')`; **First version**: May 1, 2018; **Corresponding author**: james.harper@colorado.edu"
author:
- name: James Harper, PE**; Angela Bielefeldt, PE; Amy Javernick-Will; Touer Veasna; Chris Nicoletti
  affiliation: University of Colorado Boulder; University of Colorado Boulder; University of Colorado Boulder; iDE; iDE
abstract: "With 45% of the world’s population defecating in pit latrines daily, safely managed fecal sludge has been difficult to achieve, particularly in rural communities, where households typically manage their own fecal sludge. A critical component of fecal sludge management (FSM) in these rural contexts - behavior - is known to affect FSM but is poorly understood. Using the Theory of Planned Behavior, which links contextual factors to the formation of behavioral intentions, this study examines the intentions of rural Cambodian latrine owners when their pits fill. Survey data collected from 3758 households in rural Cambodia between 2014 and 2017 were analyzed for regional and seasonal variations using structural equation modelling to answer the question “Do regional and seasonal contextual factors affect how rural latrine owners in Cambodia intend to manage their fecal sludge?”. Regional variations in FSM intentions were moderate. Latrine owners in provinces with stronger economies reported more desirable FSM intentions; however, those living in poor Oddar Meanchey province also reported more desirable FSM intentions. Thus, a strong regional economy was sufficient but not necessary for more desirable FSM intentions. FSM intentions also varied seasonally. Desirable FSM intentions peaked during April’s rice harvest (73%), when farmers are most financially stable, and fell to 50% during November’s rice planting/growing season, when farmers are least financially stable. Latrine coverage and FSM marketing history did not explain the remaining variations, indicating the need for more research. While financial stability does affect FSM intentions, other relevant contextual factors must be identified to fully describe these variations. This formative research describes a part of human decision-making that can be used to predict FSM behaviors, improve FSM behavior change methods, and improve the design of latrines and FSM processes and training to achieve safely managed sanitation."
keywords: "intention, behavior, fecal sludge management, rural, sanitation, Cambodia"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin = 1in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
bibliography: ~/Dropbox/master.bib
biblio-style: apsr
endnote: no
---
# Results

Survey data were first analyzed using multiple correspondnece analysis to show relationships between the variables.  The results of this analysis are then used in a heirarhical cluster analysis to identify groups of similar individuals within the survey data.

```{r initialize, include = FALSE}
rm(list = ls())                                      # Clear global environment
cat("\014")                                              # Clear console window
source(paste("C:/Users/James Harper/Documents/Github/", # Load custom functions
               "analyze_survey_responses/functions.R", sep = ""))
load_libraries(                                      # Install & load libraries
  c("rio", "gplots", "Amelia", "car", "fastDummies", "corrplot",
    "FactoMineR", "factoextra", "lavaan", "corrplot", "purrr", "tidyr",
    "ggplot2"))
```
```{r load_clean, include = FALSE}
# Load, clean, and summarize data
clean.raw.data = 1                                    # Clean raw data: 1 = yes
if (clean.raw.data != 1) {
  load(file = 
         paste("C:/Users/James Harper/Documents/Github/",
               "analyze_survey_responses/data/raw/surveys/",
               "describe_FSMintentions_regional_seasonal_iDE_Oct2017.RData",
               sep = ""))
} else if (clean.raw.data == 1) {
  file_to_import = 
    paste("C:/Users/James Harper/Documents/Github/",
          "analyze_survey_responses/data/raw/surveys/",
          "Customer Survey-exported30oct2017.xlsx", sep = "")
  d.surv = import(file_to_import)

  # Shorten variable (column) names
  old.col.names = names(d.surv)
  names(d.surv) = c("ID", "Creatr", "Date", "LBO", "Prov", "Dist", "Comm",
                  "Vill", "Lat", "Lng", "CLoc", "LatPur", "RLname", "RFname",
                  "RGend", "Phone", "RisC", "CLname", "CFname", "CGend",
                  "CrelR", "IDPoor", "IDPoorTyp", "M01", "M1824", "M217",
                  "M2559", "M60", "F01", "F1824", "F217", "F2559", "F60",
                  "LivRP", "VillOD", "DateSlabPur", "LatInst", "BelowGrndInst",
                  "DateBelowGrndInst", "ShltrInst", "DateInstComp",
                  "RDefBefor", "RDefBeforOthr", "FreqNeiToi", "WhoInstLat",
                  "KnwSubsdy", "RecSubsdy", "BorwLat", "CanBuyLat",
                  "UseFincOthr", "SlabTil", "Npits", "PitConfig", "NringsDir",
                  "NringsOff", "NringsOthr", "WallMat", "WallMatOthr",
                  "RoofMat", "RoofMatOthr", "MatsPurTgthr", "Cost",
                  "CostInclInst", "CostPitSlab", "CostPitSlabKnwn",
                  "CostShltrMats", "CostShltrMatsKnwn", "LabPitShltrPurTgthr",
                  "CostLabLat", "CostLabPitSlab", "CostLabPitSlabKnwn",
                  "CostLabShltr", "CostLabShltrKnwn", "LatTypOwndBefor",
                  "IntndChngDich", "IntndChng", "IntndChngOthr", "AdltUseLat",
                  "ChldUseLat", "InfLatDump", "IntndPitFull",
                  "IntndPitFullOthrAns", "Chlngs", "Satis", "Rec", "SatisSup",
                  "RecSup", "RQues", "DateSurvCreated")
  
  # Convert data formats
  for (i in 1:length(names(d.surv))) {
    if (is.character(d.surv[i][[1]])) {
      d.surv[i][[1]] = as.factor(d.surv[i][[1]])
    }
  }
  d.surv$Date = as.Date(d.surv$Date)
  d.surv$DateSlabPur = as.Date(d.surv$DateSlabPur)
  d.surv$DateBelowGrndInst = as.Date(d.surv$DateBelowGrndInst)
  d.surv$DateInstComp = as.Date(d.surv$DateInstComp)
  d.surv$DateSurvCreated = as.Date(d.surv$DateSurvCreated)
  
  # Remove unused variables
  d.surv = subset(d.surv, select = -c(ID, Creatr, Lat, Lng, CLoc, LatPur, RLname,
                                  RFname, RGend, Phone, RisC, CLname, CFname, 
                                  CGend, CrelR, RQues))
  
  # Remove data that is not applicable to this study
  d.surv = subset(d.surv, Prov != "Phnom Penh")
  
  # Remove data with low frequencies
  d.surv = subset(d.surv, Prov != "Takeo" & Prov != "Kampong Cham" &
                  Prov != "Kampong Speu")
  
  # Create Yr, Mnth, and YrMnth variables as factors
  d.surv$Yr = as.factor(format(as.Date(d.surv$Date, format = "%Y-%m-%d"),"%Y"))
  d.surv$Mnth = as.factor(format(as.Date(d.surv$Date, format = "%Y-%m-%d"),"%m"))
  d.surv$YrMnth = as.factor(paste(d.surv$Yr, d.surv$Mnth, sep = ""))
  
  # Rename responses in variables as needed
  levels(d.surv$Prov) = c("Banteay Meanchey", "Kampong Cham", "Kampong Speu",
                        "Kampong Thom", "Kandal", "Oddar Meanchey", 
                        "Phnom Penh", "Prey Veng", "Siem Reap", "Svay Rieng",
                        "Takeo")
  levels(d.surv$IDPoorTyp) = c("IDP1", "IDP2", "UnkIDP", "No")
  levels(d.surv$LivRP) = c("No", "Pond", "Rivr", "Pond", "Rivr")
  levels(d.surv$VillOD) = c("Most", "None", "Some")
  levels(d.surv$RDefBefor) = c("Bsh/Fld", "Bsh/Fld;NA/AlwysToi", "Bsh/Fld;Othr",
                             "NeiToi", "NeiToi;Bsh/Fld", "NeiToi;Bsh/Fld;Othr",
                             "NeiToi;NA/AlwysToi", "NeiToi;Othr", 
                             "NA/AlwysToi", "Othr", "NA/AlwysToi", "Riv/Pnd",
                             "Riv/Pnd;Bsh/Fld", "Riv/Pnd;NeiToi;Bsh/Fld",
                             "Riv/Pnd;Othr")
  levels(d.surv$FreqNeiToi) = c("Freq", "Freq", "Nevr", "NA/AlwysToi",
                              "NA/AlwysToi", "Some")
  levels(d.surv$WhoInstLat) = c("Self/Fam", "Self/Fam", "Gov", "Friend$",
                              "Mason", "LBO", "NGO")
  levels(d.surv$RecSubsdy) = c("DK", "No", "Yfull", "Ypart", "Yfull", "Ypart")
  levels(d.surv$BorwLat) = c("Yes", "DK", "No", "Yes")
  levels(d.surv$IntndChng) = c("Shltr", "Shltr;Othr", "Shwr", "Shltr;Shwr",
                             "Shltr;Shwr;Othr", "Shwr;Sink", 
                             "Shltr;Shwr;Sink", "Shwr;Sink;Othr",
                             "Shwr;Othr", "WtrRes", "Shltr;WtrRes",
                             "Shwr;WtrRes", "Shltr;Shwr;WtrRes",
                             "Shwr;Sink;WtrRes", "Shltr;Shwr;Sink;WtrRes",
                             "Shltr;Shwr;Sink;WtrRes;Othr",
                             "Shwr;Sink;WtrRes;Othr", "Shwr;WtrRes;Othr",
                             "Sink;WtrRes", "Shltr;Sink;WtrRes",
                             "WtrRes;Othr", "Sink", "Shltr;Sink", "Pit",
                             "Shltr;Pit", "Shltr;Pit;Othr", "Shwr;Pit",
                             "Shltr;Shwr;Pit", "Shwr;Sink;Pit",
                             "Shwr;Pit;Othr", "WtrRes;Pit",
                             "Shltr;WtrRes;Pit", "Shwr;WtrRes;Pit",
                             "Shltr;Shwr;WtrRes;Pit", "Shwr;Sink;WtrRes;Pit",
                             "Shltr;Shwr;Sink;WtrRes;Pit", "Sink;Pit",
                             "Shltr;Sink;Pit", "Pit;Othr", "NA/AlwysToi",
                             "Othr")
  levels(d.surv$AdltUseLat) = c("Freq", "Freq", "DK", "Rare", "Some")
  levels(d.surv$ChldUseLat) = c("Freq", "NoChld", "DK/NA", "DK/NA", "Rare",
                              "Some")
  levels(d.surv$InfLatDump) = c("Freq", "NoInf", "DK/NA", "DK/NA", "Rare",
                              "Some")
  levels(d.surv$IntndPitFull) = c("DK", "EmpSlf", "Pit", "Othr", "Pay", "Stop")
  levels(d.surv$Chlngs) = c("NoFlsh", "NoFlsh;Flood", "NoFlsh;Othr",
                          "NoFlsh;Ful/OvrFlw", "NoFlsh;Ful/OvrFlw;Flood",
                          "Flood", "NoWtr", "NoFlsh;NoWtr", 
                          "NoFlsh;Ful/OvrFlw;NoWtr", "NoWtr;Smels",
                          "OK", "NoFlsh", "NoWtr", "Ful/OvrFlw", "Smels",
                          "Othr", "Ful/OvrFlw", "Ful/OvrFlw", "Smels",
                          "NoFlsh;Smels", "NoFlsh;Flood;Smels",
                          "NoFlsh;Ful/OvrFlw;Smels", "Flood;Smels", 
                          "Smels;Othr", "Ful/OvrFlw;Flood;Smels")
  levels(d.surv$Satis) = c("DK", 3, 2, 4, 1, 5)
  levels(d.surv$SatisSup) = c("DK", 3, 2, 4, 1, 5)
  levels(d.surv$WallMat) = c("Bamboo / Palm Leaves / Thatch", 
                           "Bamboo / Palm Leaves / Thatch",
                           "Concrete / Brick", "Concrete / Brick",
                           "Galvanized steel", "No walls",
                           "Other", "Plastic Sheet", "Wood")
  levels(d.surv$RoofMat) = c("No roof", "Plastic Sheet", "Galvanized steel",
                           "Bamboo / Palm Leaves / Thatch",
                           "Bamboo / Palm Leaves / Thatch",
                           "Concrete / Brick", "Concrete / Brick",
                           "Galvanized steel", "No roof", "No roof",
                           "Other", "Plastic Sheet", "Tiles", "Wood")
  
  # If IDPoor is No and IDPoorType is NA, then copy IDPoor to IDPoorTyp
  for (row in 1:length(d.surv$IDPoor)) {
    if (d.surv[row,]$IDPoor == "No" & is.na(d.surv[row,]$IDPoorTyp)) {
      d.surv[row,]$IDPoorTyp = d.surv[row,]$IDPoor
    }
  }
  
  # Create new variables based on RDefBefor
  d.surv$RDefBefor_BshFld = ifelse(is.na(d.surv$RDefBefor), NA,
                                 ifelse(grepl("Bsh/Fld", d.surv$RDefBefor,
                                              fixed = TRUE), 1, 0))
  d.surv$RDefBefor_RivPnd = ifelse(is.na(d.surv$RDefBefor), NA,
                                 ifelse(grepl("Riv/Pnd", d.surv$RDefBefor,
                                              fixed = TRUE), 1, 0))
  d.surv$RDefBefor_NeiToi = ifelse(is.na(d.surv$RDefBefor), NA,
                                 ifelse(grepl("NeiToi", d.surv$RDefBefor,
                                              fixed = TRUE), 1, 0))
  d.surv$RDefBefor_Othr = ifelse(is.na(d.surv$RDefBefor), NA,
                               ifelse(grepl("Othr", d.surv$RDefBefor,
                                            fixed = TRUE), 1, 0))
  d.surv$RDefBefor_NAAlwysToi = ifelse(is.na(d.surv$RDefBefor), NA,
                                     ifelse(grepl("AlwysToi", d.surv$RDefBefor,
                                                  fixed = TRUE), 1, 0))
  d.surv$RDefBefor_BshFld = as.factor(d.surv$RDefBefor_BshFld)
  d.surv$RDefBefor_RivPnd = as.factor(d.surv$RDefBefor_RivPnd)
  d.surv$RDefBefor_NeiToi = as.factor(d.surv$RDefBefor_NeiToi)
  d.surv$RDefBefor_Othr = as.factor(d.surv$RDefBefor_Othr)
  d.surv$RDefBefor_NAAlwysToi = as.factor(d.surv$RDefBefor_NAAlwysToi)
  
  # Create new variables based on IntndChng
  d.surv$IntndChng_Shltr = ifelse(is.na(d.surv$IntndChng), NA,
                                ifelse(grepl("Shltr", d.surv$IntndChng,
                                             fixed = TRUE), "1", "0"))
  d.surv$IntndChng_Shwr = ifelse(is.na(d.surv$IntndChng), NA,
                               ifelse(grepl("Shwr", d.surv$IntndChng,
                                            fixed = TRUE), 1, 0))
  d.surv$IntndChng_Sink = ifelse(is.na(d.surv$IntndChng), NA,
                               ifelse(grepl("Sink", d.surv$IntndChng,
                                            fixed = TRUE), 1, 0))
  d.surv$IntndChng_WtrRes = ifelse(is.na(d.surv$IntndChng), NA,
                                 ifelse(grepl("WtrRes", d.surv$IntndChng,
                                              fixed = TRUE), 1, 0))
  d.surv$IntndChng_Pit = ifelse(is.na(d.surv$IntndChng), NA,
                              ifelse(grepl("Pit", d.surv$IntndChng,
                                           fixed = TRUE), 1, 0))
  d.surv$IntndChng_Othr = ifelse(is.na(d.surv$IntndChng), NA,
                               ifelse(grepl("Othr", d.surv$IntndChng,
                                            fixed = TRUE), 1, 0))
  d.surv$IntndChng_NAAlwysToi = ifelse(is.na(d.surv$IntndChng), NA,
                                     ifelse(grepl("NA/AlwysToi", 
                                                  d.surv$IntndChng,
                                                  fixed = TRUE), 1, 0))
  d.surv$IntndChng_Shltr = as.factor(d.surv$IntndChng_Shltr)
  d.surv$IntndChng_Shwr = as.factor(d.surv$IntndChng_Shwr)
  d.surv$IntndChng_Sink = as.factor(d.surv$IntndChng_Sink)
  d.surv$IntndChng_WtrRes = as.factor(d.surv$IntndChng_WtrRes)
  d.surv$IntndChng_Pit = as.factor(d.surv$IntndChng_Pit)
  d.surv$IntndChng_Othr = as.factor(d.surv$IntndChng_Othr)
  d.surv$IntndChng_NAAlwysToi = as.factor(d.surv$IntndChng_NAAlwysToi)
  
  # Create new variables based on IntndPitFull
  d.surv$IntndPitFullDes = ifelse(is.na(d.surv$IntndPitFull), NA,
                                ifelse(grepl("Pit", d.surv$IntndPitFull,
                                             fixed = TRUE) |
                                         grepl("Pay", d.surv$IntndPitFull,
                                               fixed = TRUE), "1", "0"))
  d.surv$IntndPitFullDes = as.factor(d.surv$IntndPitFullDes)
  d.surv$IntndPitFullPit = ifelse(is.na(d.surv$IntndPitFull), NA,
                                ifelse(grepl("Pit", d.surv$IntndPitFull,
                                             fixed = TRUE), "1", "0"))
  d.surv$IntndPitFullPit = as.factor(d.surv$IntndPitFullPit)
  d.surv$IntndPitFullEmpSlf = ifelse(is.na(d.surv$IntndPitFull), NA,
                                   ifelse(grepl("EmpSlf", d.surv$IntndPitFull,
                                                fixed = TRUE), "1", "0"))
  d.surv$IntndPitFullEmpSlf = as.factor(d.surv$IntndPitFullEmpSlf)
  d.surv$IntndPitFullDK = ifelse(is.na(d.surv$IntndPitFull), NA,
                               ifelse(grepl("DK", d.surv$IntndPitFull,
                                            fixed = TRUE), "1", "0"))
  d.surv$IntndPitFullDK = as.factor(d.surv$IntndPitFullDK)
  d.surv$IntndPitFullOthr = ifelse(is.na(d.surv$IntndPitFull), NA,
                                 ifelse(grepl("Othr", d.surv$IntndPitFull,
                                              fixed = TRUE), "1", "0"))
  d.surv$IntndPitFullOthr = as.factor(d.surv$IntndPitFullOthr)
  d.surv$IntndPitFullPay = ifelse(is.na(d.surv$IntndPitFull), NA,
                                ifelse(grepl("Pay", d.surv$IntndPitFull,
                                             fixed = TRUE), "1", "0"))
  d.surv$IntndPitFullPay = as.factor(d.surv$IntndPitFullPay)
  d.surv$IntndPitFullStop = ifelse(is.na(d.surv$IntndPitFull), NA,
                                 ifelse(grepl("Stop", d.surv$IntndPitFull,
                                              fixed = TRUE), "1", "0"))
  d.surv$IntndPitFullStop = as.factor(d.surv$IntndPitFullStop)
  
  # Create new variables based on Chlngs
  d.surv$ChlngsNoFlsh = ifelse(is.na(d.surv$Chlngs), NA,
                             ifelse(grepl("NoFlsh", d.surv$Chlngs,
                                          fixed = TRUE), "1", "0"))
  d.surv$ChlngsNoFlsh = as.factor(d.surv$ChlngsNoFlsh)
  d.surv$ChlngsFlood = ifelse(is.na(d.surv$Chlngs), NA,
                            ifelse(grepl("Flood", d.surv$Chlngs,
                                         fixed = TRUE), "1", "0"))
  d.surv$ChlngsFlood = as.factor(d.surv$ChlngsFlood)
  d.surv$ChlngsOthr = ifelse(is.na(d.surv$Chlngs), NA,
                           ifelse(grepl("Othr", d.surv$Chlngs,
                                        fixed = TRUE), "1", "0"))
  d.surv$ChlngsOthr = as.factor(d.surv$ChlngsOthr)
  d.surv$ChlngsFulOvrFlw = ifelse(is.na(d.surv$Chlngs), NA,
                                ifelse(grepl("Ful/OvrFlw", d.surv$Chlngs,
                                             fixed = TRUE), "1", "0"))
  d.surv$ChlngsFulOvrFlw = as.factor(d.surv$ChlngsFulOvrFlw)
  d.surv$ChlngsNoWtr = ifelse(is.na(d.surv$Chlngs), NA,
                            ifelse(grepl("NoWtr", d.surv$Chlngs,
                                         fixed = TRUE), "1", "0"))
  d.surv$ChlngsNoWtr = as.factor(d.surv$ChlngsNoWtr)
  d.surv$ChlngsSmels = ifelse(is.na(d.surv$Chlngs), NA,
                            ifelse(grepl("Smels", d.surv$Chlngs,
                                         fixed = TRUE), "1", "0"))
  d.surv$ChlngsSmels = as.factor(d.surv$ChlngsSmels)
  d.surv$ChlngsOK = ifelse(is.na(d.surv$Chlngs), NA,
                         ifelse(grepl("OK", d.surv$Chlngs,
                                      fixed = TRUE), "1", "0"))
  d.surv$ChlngsOK = as.factor(d.surv$ChlngsOK)
  
  # Create collapsed satisfaction variables for latrine and supplier
  d.surv$SatisColaps = recode(d.surv$Satis, 
                            "'DK' = 'DK'; 1 = 1; 2 = 1; 3 = 2; 4 = 3; 5 = 3")
  d.surv$SatisSupColaps = recode(d.surv$SatisSup, "'DK' = 'DK'; 1 = 1; 2 = 1; 
                               3 = 2; 4 = 3; 5 = 3")
  d.surv$SatisColapsMore = recode(d.surv$Satis, "'DK' = 'DK'; 1 = 1; 2 = 1; 3 = 1;
                                4 = 2; 5 = 2")
  d.surv$SatisSupColapsMore = recode(d.surv$SatisSup, "'DK' = 'DK'; 1 = 1; 2 = 1; 
                                   3 = 1; 4 = 2; 5 = 2")
  
  # Drop empty levels from data variables
  d.surv = droplevels(d.surv)
  
  # Create d.sets.prov for provincial-level data from other datasets
  d.sets.prov = data.frame(Prov = levels(d.surv$Prov))
  d.sets.prov$Pop13 =                                # NIS CIPS, Report 1, 2013
    c(729569, 690414, 1115965, 231390, 1156739, 922982, 578380)
  d.sets.prov$Pop13M =                               # NIS CIPS, Report 1, 2013
    c(354604, 333979, 538040, 116090, 557793, 447089, 286073)
  d.sets.prov$Pop13MPerc = d.sets.prov$Pop13M / d.sets.prov$Pop13
  d.sets.prov$Pop13F =                               # NIS CIPS, Report 1, 2013
    c(374965, 356434, 577924, 115299, 598946, 475893, 292307)
  d.sets.prov$Pop13FPerc = d.sets.prov$Pop13F / d.sets.prov$Pop13
  d.sets.prov$PopChng08to13 =                        # NIS CIPS, Report 1, 2013
    d.sets.prov$Pop13 - c(677872, 631409, 1091170, 185819, 947372, 
                          896443, 482788)
  d.sets.prov$PopChng08to13M =                        # NIS CIPS, Report 1, 2013
    d.sets.prov$Pop13 - c(331715, 307724, 529433, 93646, 453082, 439982, 231578)
  d.sets.prov$PopChng08to13MPerc = 
    d.sets.prov$PopChng08to13M / d.sets.prov$PopChng08to13
  d.sets.prov$PopChng08to13F =                        # NIS CIPS, Report 1, 2013
    d.sets.prov$Pop13 - c(346157, 323685, 561737, 92173, 494290, 456461, 251210)
  d.sets.prov$PopChng08to13FPerc = 
    d.sets.prov$PopChng08to13F / d.sets.prov$PopChng08to13
  
  
  
  d.sets.prov$PopGrow08to13Perc =                              # NIS CIPS, 2013
    c(1.47, 1.79, 0.45, 4.39, 3.99, 0.58, 3.61)
  d.sets.prov$PopDens13 =                                    # NIS CIPS, 2013
    c(109, 50, 343, 38, 237, 90, 195)
  d.sets.prov$PopDensChng08to13 =                             # NIS CIPS, 2013
    d.sets.prov$PopDens2013 - c(101, 46, 335, 30, 194, 87, 163)
  d.sets.prov$NatvLng_Khmer =                        # NIS CIPS, Report 7, 2014
    c(99.7, 98.8, 99.2, 99.7, 98.8, 99.7, 99.8)
  d.sets.prov$GenLitRat13 =                          # NIS CIPS, Report 7, 2014
    c(77.4, 68.8, 86.7, 71.6, 79.7, 75.3, 83.3)
  d.sets.prov$GenLitRatChng08to13 =                  # NIS CIPS, Report 7, 2014
    d.sets.prov$GenLitRat13 - c(78.0, 69.9, 83.7, 65.5, 80.8, 71.2, 80.1)
  d.sets.prov$GenLitRat13M =                         # NIS CIPS, Report 7, 2014
    c(82.3, 74.1, 90.8, 77.4, 86.4, 80.6, 89.9)
  d.sets.prov$GenLitRat13F =                         # NIS CIPS, Report 7, 2014
    c(72.8, 63.9, 83.1, 65.9, 73.5, 70.4, 77.1)
  d.sets.prov$GenLitRatChng08to13M =                 # NIS CIPS, Report 7, 2014
    d.sets.prov$GenLitRat13M - c(84.3, 75.6, 88.3, 72.9, 87.8, 76.9, 88.7)
  d.sets.prov$GenLitRatChng08to13F =                # NIS CIPS, Report 7, 2014
    d.sets.prov$GenLitRat13F - c(72.0, 64.5, 79.4, 58.0, 74.5, 65.9, 72.3)
  d.sets.prov$GenLitRatDiffChng08to13MF =           # + value = F improved more
    d.sets.prov$GenLitRatChng08to13F - d.sets.prov$GenLitRatChng08to13M
  d.sets.prov$EducNone =                             # NIS CIPS, Report 7, 2014
    c(26.0, 33.1, 17.5, 31.2, 21.4, 27.0, 17.4)
  d.sets.prov$EducPrimIncomp =                       # NIS CIPS, Report 7, 2014
    c(37.0, 32.2, 31.2, 34.9, 37.8, 36.6, 31.7)
  d.sets.prov$EducPrimComp =                         # NIS CIPS, Report 7, 2014
    c(21.0, 21.9, 24.5, 21.2, 24.9, 19.2, 28.7)
  d.sets.prov$EducLowSecndComp =                     # NIS CIPS, Report 7, 2014
    c(13.8, 11.5, 23.0, 11.7, 13.6, 12.1, 19.8)
  d.sets.prov$EducSecndCompNAbov =                   # NIS CIPS, Report 7, 2014
    c(2.3, 1.3, 3.7, 1.0, 2.3, 5.2, 2.4)
  d.sets.prov$EducNoneNPrimIncompM =                 # NIS CIPS, Report 7, 2014
    c(52.1, 53.9, 33.3, 53.0, 40.4, 51.2, 29.0)
  d.sets.prov$EducNoneNPrimIncompF =                 # NIS CIPS, Report 7, 2014
    c(63.2, 64.8, 48.6, 66.0, 62.6, 61.3, 54.1)
  d.sets.prov$EducPrimCompM =                        # NIS CIPS, Report 7, 2014
    c(24.1, 25.9, 27.7, 26.7, 33.2, 22.5, 36.1)
  d.sets.prov$EducPrimCompF =                        # NIS CIPS, Report 7, 2014
    c(20.5, 22.9, 25.2, 21.6, 22.8, 20.3, 26.6)
  d.sets.prov$SchlAttnd13 =                          # NIS CIPS, Report 7, 2014
    c(24.1, 23.5, 26.6, 25.2, 27.4, 27.5, 24.4)
  d.sets.prov$SchlAttnd13M =                         # NIS CIPS, Report 7, 2014
    c(26.1, 25.3, 28.8, 27.4, 31.0, 29.4, 27.9)
  d.sets.prov$SchlAttnd13F =                         # NIS CIPS, Report 7, 2014
    c(22.3, 21.8, 24.6, 23.1, 24.2, 25.8, 21.1)
  d.sets.prov$SchlAttndChng08to13 =                  # NIS CIPS, Report 7, 2014
    d.sets.prov$SchlAttnd13 - c(27.8, 29.2, 27.8, 26.9, 30.7, 27.8, 30.7)
  d.sets.prov$SchlAttndChng08to13M =                 # NIS CIPS, Report 7, 2014
    d.sets.prov$SchlAttnd13M - c(29.9, 31.5, 31.3, 28.5, 35.0, 29.9, 35.4)
  d.sets.prov$SchlAttndChng08to13F =                 # NIS CIPS, Report 7, 2014
    d.sets.prov$SchlAttnd13F - c(25.8, 27.0, 24.6, 25.2, 26.9, 25.9, 26.5)
  d.sets.prov$SchlAttndDiffChng08to13MF =           # + value = F improved more
    d.sets.prov$SchlAttndChng08to13F - d.sets.prov$SchlAttndChng08to13M
  d.sets.prov$SchlAttndPerc5dwn =                    # NIS CIPS, Report 7, 2014
    c(24.1, 23.5, 26.6, 25.2, 27.4, 27.5, 24.4)
  d.sets.prov$SchlAttndPerc614 =                     # NIS CIPS, Report 7, 2014
    c(86.1, 76.0, 88.1, 81.7, 88.7, 86.0, 86.7)
  d.sets.prov$SchlAttndPerc1519 =                    # NIS CIPS, Report 7, 2014
    c(46.6, 40.6, 55.2, 35.8, 53.2, 47.9, 55.1)
  d.sets.prov$SchlAttndPerc2024 =                    # NIS CIPS, Report 7, 2014
    c(11.5, 10.3, 22.1, 7.2, 11.8, 8.2, 12.0)
  d.sets.prov$SchlAttndPerc25up =                    # NIS CIPS, Report 7, 2014
    c(0.2, 0.1, 0.4, 0.2, 0.3, 0.4, 0.4)
  d.sets.prov$FertRat13 =                            # NIS CIPS, Report 1, 2013
    c(2.0, 3.1, 2.8, 4.0, 3.3, 3.3, 3.5)
  d.sets.prov$FertRatChng08to13 =                    # NIS CIPS, Report 1, 2013
    d.sets.prov$FertRat13 - c(2.7, 3.3, 2.8, 3.3, 2.9, 3.2, 2.8)
  
  
  # Save data variables to disk
  save(d.surv, d.sets.prov,
       file = 
         paste(getwd(),"/data/raw/surveys/",
               "describe_FSMintentions_regional_seasonal_iDE_Oct2017.RData", 
               sep = ""))
}
```
```{r summarize, include = FALSE}
# summary(d.surv)
# names(d.surv)
# print(sapply(d.surv, function(x) sum(is.na(x))))
# missmap(d.surv, main = "Missing Values in Variables", legend = F)
```
```{r MCA_setup, include = FALSE}
# Select relevant data
# names(d.surv)
select = c("Prov", "Dist", "IDPoor", "LivRP", "VillOD", 
            "FreqNeiToi", "WhoInstLat", "KnwSubsdy", "RecSubsdy", "BorwLat", 
            "SlabTil", "WallMat", "RoofMat", 
            "AdltUseLat", "ChldUseLat", "InfLatDump", "Yr", "Mnth", "YrMnth",
            "RDefBefor_BshFld", "RDefBefor_RivPnd", "RDefBefor_NeiToi",
            "IntndPitFull", 
            "ChlngsNoFlsh", "ChlngsFlood", "ChlngsOthr", "ChlngsFulOvrFlw", 
            "ChlngsNoWtr", "ChlngsSmels", "ChlngsOK",
            "SatisColapsMore", "SatisSupColapsMore", "Rec", "RecSup",
            "M01", "M1824", "M217", "M2559", "M60", "F01", "F1824", "F217", 
            "F2559", "F60")
other = c("IntndChng_Shltr", "IntndChng_Shwr", 
          "IntndChng_Sink", "IntndChng_WtrRes", "IntndChng_Pit",
          "IntndChng_Othr", "IntndChng_NAAlwysToi",
          "RDefBefor_Othr", "RDefBefor_NAAlwysToi")
d.surv.mca = subset(d.surv, select = select)
d.surv.mca = subset(d.surv.mca, !is.na(IntndPitFull))
d.surv.mca = subset(d.surv.mca, YrMnth == 201610 | YrMnth == 201611 |
                    YrMnth == 201612 | YrMnth == 201701 |
                    YrMnth == 201702 | YrMnth == 201703 |
                    YrMnth == 201704 | YrMnth == 201705 |
                    YrMnth == 201706 | YrMnth == 201707 |
                    YrMnth == 201708 | YrMnth == 201709)
d.surv.mca = subset(d.surv.mca, select = -c(YrMnth))
# Summarize data, visualize missing data, and modify as needed
# par(mfrow = c(2,1))
# for (i in 1:length(d.surv.mca)) {
#   if (i %% 2 == 0) {par(mfrow = c(2,1))}
#   plot(d.surv.mca[,i], main = colnames(d.surv.mca)[i],
#        ylab = "Count", col = "steelblue", las = 2)
# }
levels(d.surv.mca$Prov) = c("BM", "KT", "K", "OM", "PV", "SR", "SG")
levels(d.surv.mca$IDPoor) = c("NotIDPoor", "IDPoor")
colnames(d.surv.mca)[which(names(d.surv.mca) == "LivRP")] = "LivWtr"
d.surv.mca$LivWtr = recode(d.surv.mca$LivWtr, "'No' = 'NoLivWtr'; 
                         'Pond' = 'LivWtr'; 'Rivr' = 'LivWtr'")
levels(d.surv.mca$VillOD) = c("MostVillOD", "NoVillOD" ,"SomeVillOD")
levels(d.surv.mca$FreqNeiToi) = c("FreqNeiToi", "NoNeiToi" ,"AlwysToi",
                                "SomeNeiToi")
levels(d.surv.mca$WhoInstLat) = c("Slf/FamInstLat", "GovInstLat",
                                "FrndInstLat", "MasonInstLat",
                                "LBOInstLat", "NGOInstLat",
                                "DKWhoInstLat")
d.surv.mca$WhoInstLat[is.na(d.surv.mca$WhoInstLat)] = "DKWhoInstLat"
levels(d.surv.mca$KnwSubsdy) = c("KnwSubsdy", "DKSubsdy")
levels(d.surv.mca$RecSubsdy) = c("UnkSubsdy", "NoSubsdy", "FulSubsdy",
                               "PrtSubsdy")
levels(d.surv.mca$BorwLat) = c("Borw", "NoBorw", "NoBorw", "UnkBorw")
d.surv.mca$BorwLat[is.na(d.surv.mca$BorwLat)] = "UnkBorw"
levels(d.surv.mca$SlabTil) = c("NoSlabTil", "SlabTil", "UnkSlabTil")
d.surv.mca$SlabTil[is.na(d.surv.mca$SlabTil)] = "UnkSlabTil"
levels(d.surv.mca$WallMat) = c("WoodWal", "MasnWal", "StelWal", "NoWal",
                             "OthrWal", "PlstcWal", "WoodWal", "UnkWal")
d.surv.mca$WallMat[is.na(d.surv.mca$WallMat)] = "UnkWal"
levels(d.surv.mca$RoofMat) = c("NoRoof", "PlstcRoof", "StelRoof", "WoodRoof",
                             "MasnRoof", "OthrRoof", "OthrRoof", "WoodRoof",
                             "UnkRoof")
d.surv.mca$RoofMat[is.na(d.surv.mca$RoofMat)] = "UnkRoof"
levels(d.surv.mca$AdltUseLat) = c("AdltFreqLat", "AdltDKLat", "AdltRarLat", 
                                "AdltSomLat")
d.surv.mca$AdltUseLat[is.na(d.surv.mca$AdltUseLat)] = "AdltDKLat"
levels(d.surv.mca$ChldUseLat) = c("ChldFreqLat", "ChldDKLat", "ChldDKLat", 
                                "ChldRarLat", "ChldSomLat")
d.surv.mca$ChldUseLat[is.na(d.surv.mca$ChldUseLat)] = "ChldDKLat"
levels(d.surv.mca$InfLatDump) = c("InfFreqLat", "InfDKLat", "InfDKLat", 
                                "InfRarLat", "InfSomLat")
d.surv.mca$InfLatDump[is.na(d.surv.mca$InfLatDump)] = "InfDKLat"
d.surv.mca$ODBefor = 0
d.surv.mca$ODBefor =
  ifelse(d.surv.mca$RDefBefor_BshFld == 1 | d.surv.mca$RDefBefor_RivPnd == 1, 1, 0)
d.surv.mca$ODBefor = as.factor(d.surv.mca$ODBefor)
levels(d.surv.mca$ODBefor) = c("NoODBefor", "ODBefor")
levels(d.surv.mca$RDefBefor_NeiToi) = c("NoDefBeforNeiToi", "DefBeforNeiToi")
levels(d.surv.mca$ChlngsNoFlsh) = c("FlshOK", "NoFlsh", "DKFlsh")
d.surv.mca$ChlngsNoFlsh[is.na(d.surv.mca$ChlngsNoFlsh)] = "DKFlsh"
levels(d.surv.mca$ChlngsFlood) = c("NoFlood", "Flood", "DKFlood")
d.surv.mca$ChlngsFlood[is.na(d.surv.mca$ChlngsFlood)] = "DKFlood"
levels(d.surv.mca$ChlngsOthr) = c("NoOthrChlngs", "OthrChlngs", "DKOthrChlngs")
d.surv.mca$ChlngsOthr[is.na(d.surv.mca$ChlngsOthr)] = "DKOthrChlngs"
levels(d.surv.mca$ChlngsFulOvrFlw) = c("NoFulOvrflw", "FulOvrflw", "DKFulOvrflw")
d.surv.mca$ChlngsFulOvrFlw[is.na(d.surv.mca$ChlngsFulOvrFlw)] = "DKFulOvrflw"
levels(d.surv.mca$ChlngsNoWtr) = c("WtrOK", "NoWtr", "DKWtr")
d.surv.mca$ChlngsNoWtr[is.na(d.surv.mca$ChlngsNoWtr)] = "DKWtr"
levels(d.surv.mca$ChlngsSmels) = c("NoSmel", "Smel", "DKSmel")
d.surv.mca$ChlngsSmels[is.na(d.surv.mca$ChlngsSmels)] = "DKSmel"
levels(d.surv.mca$ChlngsOK) = c("Chlngs", "NoChlngs", "DKChlngs")
d.surv.mca$ChlngsOK[is.na(d.surv.mca$ChlngsOK)] = "DKChlngs"
colnames(d.surv.mca)[which(names(d.surv.mca) == "SatisColapsMore")] = "Satis"
levels(d.surv.mca$Satis) = c("UnsatLat", "SatLat", "DKSatLat")
d.surv.mca$Satis[is.na(d.surv.mca$Satis)] = "DKSatLat"
colnames(d.surv.mca)[which(names(d.surv.mca) == "SatisSupColapsMore")] = "SatisSup"
levels(d.surv.mca$SatisSup) = c("UnsatSup", "SatSup", "DKSatSup")
d.surv.mca$SatisSup[is.na(d.surv.mca$SatisSup)] = "DKSatSup"
levels(d.surv.mca$Rec) = c("NoRecLat", "RecLat", "DKRecLat")
d.surv.mca$Rec[is.na(d.surv.mca$Rec)] = "DKRecLat"
levels(d.surv.mca$RecSup) = c("NoRecSup", "RecSup")
d.surv.mca = subset(d.surv.mca, WhoInstLat != "GovInstLat")
d.surv.mca = subset(d.surv.mca, !is.na(KnwSubsdy))
d.surv.mca = subset(d.surv.mca, Yr != 2014)
d.surv.mca = subset(d.surv.mca, select = -c(RDefBefor_BshFld, RDefBefor_RivPnd))
d.surv.mca = subset(d.surv.mca, !is.na(RecSup))
d.surv.mca = subset(d.surv.mca, ChlngsOK != "DKChlngs")
d.surv.mca = subset(d.surv.mca, SlabTil != "UnkSlabTil")
d.surv.mca = subset(d.surv.mca, RoofMat != "UnkRoof")
d.surv.mca = subset(d.surv.mca, AdltUseLat != "AdltDKLat")
d.surv.mca = subset(d.surv.mca, Rec != "DKRecLat")
d.surv.mca = subset(d.surv.mca, BorwLat != "UnkBorw")
d.surv.mca$F217[is.na(d.surv.mca$F217)] = 
  mean(d.surv.mca$F217[!is.na(d.surv.mca$F217)])
d.surv.mca$M1824[is.na(d.surv.mca$M1824)] = 
  mean(d.surv.mca$M1824[!is.na(d.surv.mca$M1824)])
d.surv.mca = droplevels(d.surv.mca)
# summary(d.surv.mca, maxsum = 12)
# print(sapply(d.surv.mca, function(x) sum(is.na(x))))
```
```{r MCA_analyze, include = FALSE}
varTable(d.surv.mca)
quali.sup1 = c(1:2, 17:18)
quanti.sup1 = c(32:41)
quali.sup2 = c(2, 4:16, 19, 21, 23:27, 30)
quanti.sup2 = c(32:41)
res.mca = MCA(d.surv.mca, quanti.sup = quanti.sup1, quali.sup = quali.sup1,
              na.method = "NA", graph = FALSE)
```

The data analyzed with multiple correspondence analysis were first summarized by frequency using bar charts of each variable.

```{r MCA_summarize, echo = FALSE, fig.height = 2.5, fig.align = "center"}
par(mfrow = c(1,3), mar = c(6.5,4,3,1))
for (i in 1:length(d.surv.mca)) {
  plot(d.surv.mca[,i], main = colnames(d.surv.mca)[i],
       ylab = "Count", col = "steelblue", las = 2)
}

# plot(d.surv.mca[,1], main = colnames(d.surv.mca)[1],
#        ylab = "Count", col = "steelblue", las = 2)
# plot(d.surv.mca[,2], main = colnames(d.surv.mca)[2],
#        ylab = "Count", col = "steelblue", las = 2)
# plot(d.surv.mca[,3], main = colnames(d.surv.mca)[3],
#        ylab = "Count", col = "steelblue", las = 2)

# d.surv.mca %>%
#   gather() %>% 
#   ggplot(aes(value)) +
#     facet_wrap(~ key, scales = "free") +
#     geom_bar()
```

The eigenvalues of the first six dimensions are shown below and describe the proportion of variances retained by each dimension.  A scree plot shows the percentages of inertia explained by each MCA dimension.

```{r MCA_results_eigenvalues, echo = FALSE}
par(mfrow = c(1, 1))
# print(res.mca)
res.mca.eigs = get_eigenvalue(res.mca)
# head(round(res.mca.eigs, 2))
fviz_screeplot(res.mca, addlabels = TRUE, ylim = c(0, 50))
```

A biplot of individuals and variable categories (responses) shows the global patterns within the survey data.  Rows (individuals) are represented by blue points and columns (variable categories) by red triangles.  The distance between any row points or column points gives a measure of their similarity (or dissimilarity). Row points with similar profile are closed on the factor map. The same holds true for column points.

```{r MCA_results_biplot, echo = FALSE}
fviz_mca_biplot(res.mca, repel = FALSE, ggtheme = theme_minimal())
```

##Variable Categories

Results for variable categories are shown below.  The plot of correlations between variables and the MCA dimensions helps to identify variables that are the most correlated with each dimension. The squared correlations between variables and the dimensions are used as coordinates.

```{r MCA_results_vars1, echo = FALSE}
fviz_mca_var(res.mca, choice = "mca.cor", repel = TRUE,      # Cor, vars & dims
             ggtheme = theme_minimal())
```

The coordinates of each variable are shown in table and graphical format.  The plot shows the relationships between variable categories. Variable categories with a similar profile are grouped together.  Negatively correlated variable categories are positioned on opposite sides of the plot origin (opposing quadrants).  The distance between category points and the origin measures the quality of the variable category on the factor map. Category points that are far away from the origin are well represented on the factor map.

```{r MCA_results_vars2, echo = FALSE}
res.mca.vars = get_mca_var(res.mca)
# round(res.mca.vars$coord, 2)
fviz_mca_var(res.mca, repel = TRUE, ggtheme = theme_minimal())
# fviz_mca_var(res.mca, col.var = "black", shape.var = 15, repel = TRUE)
```

##Quality of Representation of Variable Categories

Dimensions 1 and 2 are sufficient to retain `r res.mca.eigs[1,2] + res.mca.eigs[2,2]`% of the total inertia (variation) contained in the data. Not all the points are equally well displayed in the two dimensions.

The quality of the representation is called the squared cosine (cos2), which measures the degree of association between variable categories and a particular axis. If a variable category is well represented by two dimensions, the sum of the cos2 value for each dimension is near one.  A bar plot can also be used.

Note that variables that have a low cos2 value are not well represented by the dimensions indicated. This implies that the position of these points on the scatter plot should be interpreted with some caution. A higher dimensional solution is probably necessary.

```{r MCA_results_vars3, echo = FALSE}
round(res.mca.vars$cos2, 4)
fviz_cos2(res.mca, choice = "var", axes = 1:2)
```

Coloring each variable category by its cos2 values produces a color-gradient plot.

```{r MCA_results_vars4, echo = FALSE}
fviz_mca_var(res.mca, col.var = "cos2", repel = TRUE, 
             ggtheme = theme_minimal(),
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

The transparency of each variable category may also be changed based on its cos2 value.

```{r MCA_results_vars5, echo = FALSE}
fviz_mca_var(res.mca, alpha.var = "cos2", repel = TRUE, 
             ggtheme = theme_minimal())
```

Cos2 values may also be visualized using a correlation plot.

```{r MCA_results_vars6, echo = FALSE}
corrplot(res.mca.vars$cos2, is.corr = FALSE)
```

**Contribution of variable categories to the dimensions**

The percent contribution of each variable category to the definition of each MCA dimension is shown below.  Variable categories with larger contributions define a dimension more than other variable categories and are thus most important in explaining the variability in the dataset.  Bar plots are also used to show these results.  The red dashed line on the plot indicates the expected average value if contributions were uniform.

```{r MCA_results_vars7, echo = FALSE}
round(res.mca.vars$contrib, 3)
fviz_contrib(res.mca, choice = "var", axes = 1, top = 15)
fviz_contrib(res.mca, choice = "var", axes = 2, top = 15)
```

The total contributions to dimension 1 and 2 described below as a table and highlighted on the scatter plot.  The plot describes how each variable category contributes to which pole of each dimension.

```{r MCA_results_vars8, echo = FALSE}
fviz_contrib(res.mca, choice = "var", axes = 1:2, top = 15)
fviz_mca_var(res.mca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, 
             ggtheme = theme_minimal())
```

The transparency of each variable category may also be changed based on its contribution.

```{r MCA_results_vars9, echo = FALSE}
fviz_mca_var(res.mca, alpha.var = "contrib",
             repel = TRUE,
             ggtheme = theme_minimal())
```




             
             


<!-- res.mca.ind = get_mca_ind(res.mca) -->
<!-- print(res.mca.ind) -->
<!-- head(res.mca.ind$coord) -->
<!-- head(res.mca.ind$contrib) -->
<!-- head(res.mca.ind$cos2) -->
<!-- # fviz_mca_ind(res.mca, col.ind = "cos2", -->
<!-- #              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), -->
<!-- #              repel = TRUE, -->
<!-- #              ggtheme = theme_minimal()) -->
<!-- fviz_mca_ind(res.mca, -->
<!--              label = "none", # hide individual labels -->
<!--              habillage = d.surv.mca$Prov, # color by groups -->
<!--              # palette = c("#00AFBB", "#E7B800"), -->
<!--              addEllipses = TRUE, ellipse.type = "confidence", -->
<!--              ggtheme = theme_minimal()) -->

<!-- ```{r cluster, include = FALSE} -->
<!-- res.hcpc = HCPC(res.mca, graph = FALSE, max = 3) -->
<!-- fviz_dend(res.hcpc, show_labels = FALSE)   # Dendrogram -->
<!-- fviz_cluster(res.hcpc, geom = "point", main = "Factor map")  # Indiv factor map -->
<!-- res.hcpc$desc.var$test.chi2   # Description by variables -->
<!-- res.hcpc$desc.var$category   # Description by variable categories -->
<!-- res.hcpc$desc.axes   # Description by princial components -->
<!-- res.hcpc$desc.ind$para   # Description by individuals -->
<!-- ``` -->



# Introduction

Academic workflow, certainly in political science, is at a crossroads. The *American Journal of Political Science* (*AJPS*) announced a (my words) ["show your work" initiative](http://ajps.org/2015/03/26/the-ajps-replication-policy-innovations-and-revisions/) in which authors who are tentatively accepted for publication at the journal must hand over the raw code and data that produced the results shown in the manuscript. The editorial team at *AJPS* then reproduces the code from the manuscript. Pending successful replication, the manuscript moves toward publication. The *AJPS* might be at the fore of this movement, and it could be the most aggressive among political science journals, but other journals in our field have signed the joint [Data Access & Research Transparency](http://www.dartstatement.org/) (DART) initiative. This, at a bare minimum, requires uploading code from quantitatively-oriented published articles to in-house directories hosted by the journal or to services like [Dataverse](http://dataverse.org/). 

There are workflow implications to the Lacour controversy as well. Political science, for the foreseeable future, will struggle with the extent of [the data fraud perpetrated by Michael Lacour](http://stanford.edu/~dbroock/broockman_kalla_aronow_lg_irregularities.pdf) in an article co-authored with Donald P. Green in *Science*, the general scientific journal of record in the United States. A failure to reproduce LaCour's results with different samples uncovered a comprehensive effort by LaCour to "fake" data that provided results to what we felt or believed to be true [(i.e. "truthiness")](http://chronicle.com/article/LAffaire-LaCour/230905/). However, [fake data can have real consequences](http://kieranhealy.org/blog/archives/2015/05/20/fake-science-real-consequences/) for both the researcher and those who want to learn from it and use it for various purposes. Even research done honestly may suffer the same fate if researchers are not diligent in their workflow.

These recent events underscore the DART push and cast a shadow over our workflow. However, good workflow has always been an issue in our discipline. Cloud storage services like [Dropbox](http://www.dropbox.com) are still relatively new among political scientists. Without cloud storage, previous workflow left open the possibility that work between a home computer and an office computer was lost as a function of a corrupted thumb drive, an overheated power supply, or, among other things, the wave of viruses that [would particularly affect Microsoft users every summer](http://money.cnn.com/2003/11/05/technology/microsoftbounty/). Social sciences, [unlike engineering](http://kieranhealy.org/blog/archives/2014/01/23/plain-text/), have traditionally relied on software like Microsoft Word for manuscript preparation though any word processor reduces workflow to a series of clicks and strokes on a keyboard. This is [a terrible way to track changes](http://www.nytimes.com/2013/04/19/opinion/krugman-the-excel-depression.html) or maintain version control. The addition of collaborators only compounds all the aforementioned issues. The proverbial left hand may not know what the right hand is doing.

I think there is reason for optimism. We only struggle with it now because we have tools like [R Markdown](http://rmarkdown.rstudio.com/) and [Pandoc](http://pandoc.org/), more generally, that make significant strides in workflow. LaTeX resolved earlier issues of corrupted binary files by reducing documents to raw markup that was little more than raw text and revisions that could be easily kept as ["commented" text](http://tex.stackexchange.com/questions/11177/how-to-write-hidden-notes-in-a-latex-file). However, for all its benefits (including pretty PDFs), [LaTeX is *ugly* code](http://www-rohan.sdsu.edu/~aty/bibliog/latex/gripe.html) and does not provide means of seamlessly working with the actual data analysis itself. R Markdown both eliminates markup and allows the author and her collaborators to write and reproduce the manuscript in one fell swoop.

# Getting Started with YAML

The lion's share of a R Markdown document will be raw text, though the front matter may be the most important part of the document. R Markdown uses [YAML](http://www.yaml.org/) for its metadata and the fields differ from [what an author would use for a Beamer presentation](http://svmiller.com/blog/2015/02/moving-from-beamer-to-r-markdown/). I provide a sample YAML metadata largely taken from this exact document and explain it below.

```{r eval=FALSE}
---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: ~/Dropbox/miscelanea/svm-r-markdown-templates/svm-latex-ms.tex
title: "A Pandoc Markdown Article Starter and Template"
thanks: "Replication files are available on the author's Github account..."
author:
- name: Steven V. Miller
  affiliation: Clemson University
- name: Mary Margaret Albright
  affiliation: Pendelton State University
- name: Rembrandt Q. Einstein
  affiliation: Springfield University
abstract: "This document provides an introduction to R Markdown, argues for its..."
keywords: "pandoc, r markdown, knitr"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
bibliography: ~/Dropbox/master.bib
biblio-style: apsr
---
```

`output:` will tell R Markdown we want a PDF document rendered with LaTeX. Since we are adding a fair bit of custom options to this call, we specify `pdf_document:` on the next line (with, importantly, a two-space indent). We specify additional output-level options underneath it, each are indented with four spaces. `citation_package: natbib` tells R Markdown to use `natbib` to handle bibliographic citations.[^natbib] Thereafter, the next line (`keep_tex: true`) tells R Markdown to render a raw `.tex` file along with the PDF document. This is useful for both debugging and the publication stage, when the editorial team will ask for the raw `.tex` so that they could render it and later provide page proofs. The next line `fig_caption: true` tells R Markdown to make sure that whatever images are included in the document are treated as figures in which our caption in brackets in a Markdown call is treated as the caption in the figure. The next line (`latex_engine: pdflatex`) tells R Markdown to use pdflatex and not some other option like `lualatex`. For my template, I'm pretty sure this is mandatory.[^pdflatex]

[^natbib]: R Markdown can use Pandoc's native bibliography management system or even `biblatex`, but I've found that it chokes with some of the more advanced stuff I've done with my .bib file over the years. For example, I've been diligent about special characters (e.g. umlauts and acute accents) in author names in my .bib file, but Pandoc's native citation system will choke on these characters in a .bib file. I effectively need `natbib` for my own projects.
[^pdflatex]: The main reason I still use `pdflatex` (and most readers probably do as well) is because of LaTeX fonts. [Unlike others](http://www-rohan.sdsu.edu/~aty/bibliog/latex/gripe.html), I find standard LaTeX fonts to be appealing.

The next line (`template: ...`) tells R Markdown to use my custom LaTeX template.[^path] While I will own any errors in the code, I confess to "Frankensteining" this template from [the default LaTeX template](https://github.com/jgm/pandoc-templates) from Pandoc, [Kieran Healy's LaTeX template](https://github.com/kjhealy/pandoc-templates/tree/master/templates), and liberally using raw TeX from the [Association for Computing Machinery's (ACM) LaTeX template](https://www.acm.org/publications/article-templates/acm-latex-style-guide). I rather like that template since it resembles standard manuscripts when they are published in some of our more prominent journals. I will continue with a description of the YAML metadata in the next paragraph, though invite the curious reader to scroll to the end of the accompanying post to see the PDF this template produces.


[^path]: Notice that the path is relative. The user can, if she wishes, install this in the default Pandoc directory. I don't think this is necessary. Just be mindful of wherever the template is placed. Importantly, `~` is used in R to find the home directory (not necessarily the working directory). It is equivalent to saying `/home/steve` in Linux, or `/Users/steve` on a Mac, in my case.

The next fields get to the heart of the document itself. `title:` is, intuitively, the title of the manuscript. Do note that fields like `title:` do not have to be in quotation marks, but must be in quotation marks if the title of the document includes a colon. That said, the only reason to use a colon in an article title is if it is followed by a subtitle, hence the optional field (`subtitle:`). Notice I "comment out" the subtitle in the above example with a pound sign since this particular document does not have a subtitle. If `thanks:` is included and has an accompanying entry, the ensuing title of the document gets an asterisk and a footnote. This field is typically used to advise readers that the document is a working paper or is forthcoming in a journal.

The next field (`author:`) is a divergence from standard YAML, but I think it is useful. I will also confess to pilfering this idea from Kieran Healy's template. Typically, multiple authors for a given document are separated by an `\and` in this field. However, standard LaTeX then creates a tabular field separating multiple authors that is somewhat restrictive and not easy to override. As a result, I use this setup (again, taken from Kieran Healy) to sidestep the restrictive rendering of authors in the standard `\maketitle` tag. After `author:`, enter `- name:` (no space before the dash) and fill in the field with the first author. On the next line, enter two spaces, followed by `affiliation:` and the institute or university affiliation of the first author.

Do notice this can be repeated for however many co-authors there are to a manuscript. The rendered PDF will enter each co-author in a new line in a manner similar to journals like *American Journal of Political Science*, *American Political Science Review*, or *Journal of Politics*.

The next two fields pertain to the frontmatter of a manuscript. They should also be intuitive for the reader. `abstract` should contain the abstract and `keywords` should contain some keywords that describe the research project. Both fields are optional, though are practically mandatory. Every manuscript requires an abstract and some journals---especially those published by Sage---request them with submitted manuscripts. My template also includes these keywords in the PDF's metadata.

`date` comes standard with R Markdown and you can use it to enter the date of the most recent compile. I typically include the date of the last compile for a working paper in the `thanks:` field, so this field currently does not do anything in my Markdown-LaTeX manuscript template. I include it in my YAML as a legacy, basically.

The next items are optional and cosmetic. `geometry:` is a standard option in LaTeX. I set the margins at one inch, and you probably should too. `fontfamily:` is optional, but I use it to specify the Palatino font. The default option is Computer Modern Roman. `fontsize:` sets, intuitively, the font size. The default is 10-point, but I prefer 11-point. `spacing:` is an optional field. If it is set as "double", the ensuing document is double-spaced. "single" is the only other valid entry for this field, though not including the entry in the YAML metadata amounts to singlespacing the document by default. Notice I have this "commented out" in the example code.

The final two options pertain to the bibliography. `bibliography:` specifies the location of the .bib file, so the author could make citations in the manuscript. `biblio-style` specifies the type of bibliography to use. You'll typically set this as APSR. You could also specify the relative path of [my *Journal of Peace Research* .bst file](http://svmiller.com/miscellany/journal-of-peace-research-bst-file/) if you are submitting to that journal.

# Getting Started with Markdown Syntax

There are a lot of cheatsheets and reference guides for Markdown (e.g. [Adam Prichard](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet), [Assemble](http://assemble.io/docs/Cheatsheet-Markdown.html), [Rstudio](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf), [Rstudio again](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf), [Scott Boms](http://scottboms.com/downloads/documentation/markdown_cheatsheet.pdf), [Daring Fireball](https://daringfireball.net/projects/markdown/syntax), among, I'm sure, several others). I encourage the reader to look at those, though I will retread these references here with a minimal working example below.

```markdown

# Introduction

**Lorem ipsum** dolor *sit amet*. 

- Single asterisks italicize text *like this*. 
- Double asterisks embolden text **like this**.

Start a new paragraph with a blank line separating paragraphs.

- This will start an unordered list environment, and this will be the first item.
- This will be a second item.
- A third item.
    - Four spaces and a dash create a sublist and this item in it.
- The fourth item.
    
1. This starts a numerical list.
2. This is no. 2 in the numerical list.
    
# This Starts A New Section
## This is a Subsection
### This is a Subsubsection
#### This starts a Paragraph Block.

> This will create a block quote, if you want one.

Want a table? This will create one.

Table Header  | Second Header
------------- | -------------
Table Cell    | Cell 2
Cell 3        | Cell 4 

Note that the separators *do not* have to be aligned.

Want an image? This will do it.

![caption for my image](path/to/image.jpg)

`fig_caption: yes` will provide a caption. Put that in the YAML metadata.

Almost forgot about creating a footnote.[^1] This will do it again.[^2]

[^1]: The first footnote
[^2]: The second footnote

Want to cite something? 

- Find your biblatexkey in your bib file.
- Put an @ before it, like @smith1984, or whatever it is.
- @smith1984 creates an in-text citation (e.g. Smith (1984) says...)
- [@smith1984] creates a parenthetical citation (Smith, 1984)

That'll also automatically create a reference list at the end of the document.

[In-text link to Google](http://google.com) as well.
```

That's honestly it. Markdown takes the chore of markup from your manuscript (hence: "Markdown").

On that note, you could easily pass most LaTeX code through Markdown if you're writing a LaTeX document. However, you don't need to do this (unless you're using the math environment) and probably shouldn't anyway if you intend to share your document in HTML as well.

# Using R Markdown with Knitr

Perhaps the greatest intrigue of R Markdown comes with the [`knitr` package](http://yihui.name/knitr/) provided by @xie2013ddrk. In other words, the author can, if she chooses, do the analysis in the Markdown document itself and compile/execute it in R.

Take, for example, this simple exercise using the `voteincome` data from the `Zelig` package. Suppose I want to explain the decision to vote using data from this package. I load in the data, clean the data, run the analyses, and present the results as a coefficient plot.

Here's what this code looks like. All I did was create a code display, which starts with three *backticks* (i.e. those ticks next to the number 1 key on your keyboard) and ends with three backticks on another line. On the first line of backticks (i.e. to start the code display) enter `{r, eval=FALSE, tidy=TRUE}`. The `eval=FALSE` option just displays the R code (and does not run it), `tidy=TRUE` wraps long code so it does not run off the page.

Within that code display, I enter my R code like this.


```{r, eval=FALSE, tidy = TRUE}
suppressMessages(library(Zelig))
suppressMessages(library(arm))
suppressMessages(library(coefplot))

data(voteincome)

voteincome$z.age <- arm::rescale(voteincome$age)
voteincome$z.education <- arm::rescale(voteincome$education)
voteincome$z.income <- arm::rescale(voteincome$income)

M1 <- glm(vote ~ z.age + female + z.education + z.income,
            data=voteincome, family=binomial)

coefplot(M1)
```

The implications for workflow are faily substantial. Authors can rather quickly display the code they used to run the analyses in the document itself (likely in the appendix). As such, there's little guesswork for reviewers and editors in understanding what the author did in the analyses reported in the manuscript.

It doesn't end there. In fact, here's what happens when `eval=FALSE` is omitted or changed to `eval=TRUE`. Now, the code runs within R. Observe.

```{r, eval=TRUE, tidy = TRUE, cache=FALSE, fig.cap="A Coefficient Plot"}
suppressMessages(library(Zelig))
suppressMessages(library(arm))


data(voteincome)

voteincome$z.age <- arm::rescale(voteincome$age)
voteincome$z.education <- arm::rescale(voteincome$education)
voteincome$z.income <- arm::rescale(voteincome$income)

M1 <- glm(vote ~ z.age + female + z.education + z.income,
            data=voteincome, family=binomial)

arm::coefplot(M1)
```

To get `knitr` to present the results of a table, add `results="asis"` to the brackets to start the R code chunk. The ensuing output will look like this (though the table may come on the next page).

```{r, eval=TRUE, tidy = TRUE, size="small", cache=FALSE, results="asis"}
suppressMessages(library(Zelig))
suppressMessages(library(stargazer))
suppressMessages(library(arm))

data(voteincome)

voteincome$z.age <- arm::rescale(voteincome$age)
voteincome$z.education <- arm::rescale(voteincome$education)
voteincome$z.income <- arm::rescale(voteincome$income)


M1 <- glm(vote ~ z.age + female + z.education + z.income,
            data=voteincome, family=binomial)

stargazer(M1, title="A Handsome Table", header=FALSE)
```

Adding `echo="FALSE"` inside the brackets to start the R chunk will omit the presentation of the R commands. It will just present the table. This provides substantial opportunity for authors in doing their analyses. Now, the analysis and presentation in the form of a polished manuscript can be effectively simultaneous.[^4]

[^4]: I'm not sure if I'm ready to commit to this myself since my workflow is still largely derived from [Rob J. Hyndman's example](http://robjhyndman.com/hyndsight/workflow-in-r/). However, *knitr* has endless potential, especially when analyses can stored in cache, saved as chunks, or loaded in the preamble of a document to reference later in the manuscript.




<!--
# References
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\vspace*{-0.2in}
\noindent
-->
